{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfbac98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 21431 entries, 0 to 21430\n",
      "Columns: 140 entries, L02_001 to geometry\n",
      "dtypes: float64(4), geometry(1), int32(69), object(66)\n",
      "memory usage: 17.2+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import warnings\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from sklearn.neighbors import BallTree\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "input_path = '../input/'\n",
    "gdf_land = gpd.read_file(os.path.join(input_path, 'L02-25.geojson'))\n",
    "df_land = gdf_land.copy()\n",
    "df_land['price'] = df_land['L02_006']\n",
    "df = pd.read_csv(os.path.join(input_path, 'train.csv'))\n",
    "test = pd.read_csv(os.path.join(input_path, 'test.csv'))\n",
    "gdf_land.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e64d7d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†é–¢æ•°ï¼ç‰¹å¾´é‡ä½œæˆã‚‚ã“ã“ã§\n",
    "def preprocess_data(input_df, df_land, is_train=True, fill_value = None):\n",
    "    \"\"\"\n",
    "    é§…æƒ…å ±ã¯ä¸€æ—¦ç„¡è¦–ï¼\n",
    "    ã€Œå·¨å¤§ãªã‚´ãƒŸãƒ‡ãƒ¼ã‚¿ã€ã®å‰Šé™¤ã¨ã€ã€Œåœ°ä¾¡ãƒ»ç¯‰å¹´æ•°ã€ã ã‘ã«é›†ä¸­ã—ãŸã‚·ãƒ³ãƒ—ãƒ«ç‰ˆ\n",
    "    \"\"\"\n",
    "    df = input_df.copy()\n",
    "    \n",
    "    # -----------------------------------------------------\n",
    "    # 0. ã€Trainã®ã¿ã€‘ãƒã‚ºãƒ¬å€¤ãªã©ã®å‰Šé™¤\n",
    "    # -----------------------------------------------------\n",
    "    if is_train:\n",
    "        # 1. é¢ç©ãƒ•ã‚£ãƒ«ã‚¿\n",
    "        # é¢ç©500ã¡ä»¥ä¸Šã¯ã‚«ãƒƒãƒˆ\n",
    "        df = df[df['unit_area'] < 500] \n",
    "        \n",
    "        # 2. å˜ä¾¡ãŒãŠã‹ã—ã„åœŸåœ°ã‚’å‰Šé™¤\n",
    "        # å˜ä¾¡(å††/ã¡)ã‚’è¨ˆç®—\n",
    "        temp_unit_price = df['money_room'] / df['unit_area']\n",
    "        \n",
    "        # ã€Œå˜ä¾¡ãŒ1ä¸‡å††/ã¡ ä»¥ä¸‹ã€ã¯ã€åŸé‡ã‚„å±±æ—ãªã®ã§æ¨ã¦ã‚‹\n",
    "        df = df[temp_unit_price > 10000] \n",
    "        \n",
    "        # 3. ã€Œé«˜ã™ãã‚‹å˜ä¾¡ã€ã‚‚ãƒã‚¤ã‚ºã«ãªã‚‹ã®ã§ã‚­ãƒ£ãƒƒãƒ—ã‚’è¨­ã‘ã‚‹\n",
    "        df = df[temp_unit_price < 10000000]\n",
    "\n",
    "    else:\n",
    "        # Testãƒ‡ãƒ¼ã‚¿ã®å ´åˆã€é¢ç©ã®æ¬ æå€¤ã‚’ä¸­å¤®å€¤ã§åŸ‹ã‚ã‚‹\n",
    "        fill_val = fill_value if fill_value else df['unit_area'].median()\n",
    "        if fill_value is not None:\n",
    "            df['unit_area'] = df['unit_area'].fillna(fill_value)\n",
    "    # -----------------------------------------------------\n",
    "    # 1. é§…æƒ…å ± (ä»Šå¾Œå®Ÿè£…äºˆå®š)\n",
    "    # -----------------------------------------------------\n",
    "    # â€»ã‚«ãƒ©ãƒ åãŒç”»åƒé€šã‚Š (bus_time1, walk_distance1) å‰æã§æ›¸ãã¾ã™\n",
    "    # ã‚‚ã—é•ã£ãŸã‚‰ df.columns ã§ç¢ºèªã—ã¦æ›¸ãæ›ãˆã¦ãã ã•ã„ï¼\n",
    "    \n",
    "    # å¿…è¦ãªåˆ—ãŒã‚ã‚‹ã‹ç¢ºèª\n",
    "    if 'walk_distance1' in df.columns:\n",
    "        \n",
    "        def calc_access_time(row, suffix):\n",
    "            \"\"\"\n",
    "            suffix: '1' ã¾ãŸã¯ '2' ã‚’æŒ‡å®š\n",
    "            \"\"\"\n",
    "            # 1. ãƒ‡ãƒ¼ã‚¿ã®å–å¾— (æ¬ æå€¤ã¯0ã«ã—ã¦ãŠã)\n",
    "            w_dist = row.get(f'walk_distance{suffix}', np.nan)\n",
    "            b_time = row.get(f'bus_time{suffix}', np.nan)\n",
    "            \n",
    "            # ãƒ‡ãƒ¼ã‚¿ãŒå…¨ããªã„å ´åˆã¯ã€Œä¸æ˜(ç„¡é™å¤§)ã€\n",
    "            if pd.isna(w_dist) and pd.isna(b_time):\n",
    "                return 999.0 # ã‚ã¨ã§minã‚’å–ã‚‹ã¨ãã«è² ã‘ã‚‹ã‚ˆã†ã«å¤§ããã™ã‚‹\n",
    "\n",
    "            # NaNã‚’0æ‰±ã„ã§è¨ˆç®—ç”¨ã«ç¢ºä¿\n",
    "            w_dist_val = 0 if pd.isna(w_dist) else w_dist\n",
    "            b_time_val = 0 if pd.isna(b_time) else b_time\n",
    "            \n",
    "            # 2. å¾’æ­©æ™‚é–“ã‚’è¨ˆç®— (80m = 1åˆ†\n",
    "            walk_min = w_dist_val / 80.0\n",
    "            \n",
    "            # 3. ãƒ­ã‚¸ãƒƒã‚¯åˆ†å²\n",
    "            if b_time_val > 0:\n",
    "                # ã€ãƒ‘ã‚¿ãƒ¼ãƒ³A: ãƒã‚¹åˆ©ç”¨ã€‘\n",
    "                # æ™‚é–“ = ãƒã‚¹ä¹—è»Šæ™‚é–“ + ãƒã‚¹åœã‹ã‚‰ã®å¾’æ­© + å¾…ã¡æ™‚é–“ãƒšãƒŠãƒ«ãƒ†ã‚£(10åˆ†)\n",
    "                return b_time_val + walk_min + 10.0\n",
    "            else:\n",
    "                # ã€ãƒ‘ã‚¿ãƒ¼ãƒ³B: å¾’æ­©ã®ã¿ã€‘\n",
    "                # æ™‚é–“ = é§…ã‹ã‚‰ã®å¾’æ­©\n",
    "                return walk_min\n",
    "\n",
    "        # ãƒ«ãƒ¼ãƒˆ1ã¨ãƒ«ãƒ¼ãƒˆ2ã€ãã‚Œãã‚Œã®æ‰€è¦æ™‚é–“ã‚’è¨ˆç®—\n",
    "        df['access_time_1'] = df.apply(lambda x: calc_access_time(x, '1'), axis=1)\n",
    "        df['access_time_2'] = df.apply(lambda x: calc_access_time(x, '2'), axis=1)\n",
    "        \n",
    "        # ã€Œ1ã€ã¨ã€Œ2ã€ã®ã†ã¡ã€æ™‚é–“ãŒçŸ­ã„æ–¹ï¼ˆï¼è¿‘ã„æ–¹ï¼‰ã‚’æ¡ç”¨ï¼\n",
    "        # ã©ã£ã¡ã‚‚999(ä¸æ˜)ãªã‚‰ã€æœ€çµ‚çš„ã«120åˆ†ã§åŸ‹ã‚ã‚‹\n",
    "        df['station_minutes'] = df[['access_time_1', 'access_time_2']].min(axis=1)\n",
    "        \n",
    "        # æœ€çµ‚çš„ãªæ¬ æå€¤åŸ‹ã‚ (ç”°èˆå¯¾ç­–)\n",
    "        # 999ã®ã¾ã¾æ®‹ã£ãŸã‚„ã¤ã¯ã€Œé§…å¾’æ­©åœå¤–ã€ã¨ã—ã¦120åˆ†ã«ã™ã‚‹\n",
    "        df['station_minutes'] = df['station_minutes'].replace(999.0, 120.0)\n",
    "        \n",
    "        # å¿µã®ãŸã‚ station_minutes è‡ªä½“ãŒNaNã®ã‚„ã¤ã‚‚åŸ‹ã‚ã‚‹\n",
    "        df['station_minutes'] = df['station_minutes'].fillna(120.0)\n",
    "\n",
    "        # ä¸è¦ã«ãªã£ãŸä¸€æ™‚çš„ãªåˆ—ã‚’å‰Šé™¤ï¼ˆãƒ¡ãƒ¢ãƒªç¯€ç´„ï¼‰\n",
    "        df.drop(['access_time_1', 'access_time_2'], axis=1, inplace=True)\n",
    "        \n",
    "        # ã‚«ãƒ†ã‚´ãƒªç”¨ (æ²¿ç·šåãªã©ã¯ _1 ã®æ–¹ã‚’æ­£ã¨ã—ã¦æ¡ç”¨ã—ã¦ãŠã)\n",
    "        if 'rosen_name1' in df.columns:\n",
    "            df['line_name'] = df['rosen_name1']\n",
    "            df['station_name'] = df['eki_name1']\n",
    "        else:\n",
    "            df['line_name'] = 'unknown'\n",
    "            df['station_name'] = 'unknown'\n",
    "\n",
    "    else:\n",
    "        # ãã‚‚ãã‚‚åˆ—ãŒãªã„å ´åˆ\n",
    "        df['station_minutes'] = 120.0\n",
    "        df['line_name'] = 'unknown'\n",
    "        df['station_name'] = 'unknown'\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # 2. ç¯‰å¹´æ•°ã®è¨ˆç®— \n",
    "    # -----------------------------------------------------\n",
    "    df['year_built'] = pd.to_numeric(df['year_built'], errors='coerce')\n",
    "    df['year_built'] = df['year_built'].fillna(df['year_built'].median())\n",
    "    df['temp_time'] = pd.to_datetime(df['year_built'].astype(int).astype(str), format='%Y%m', errors='coerce')\n",
    "    \n",
    "    base_date = pd.to_datetime('2025-12-01')\n",
    "    df['building_month'] = (base_date - df['temp_time']).dt.days / 30.44\n",
    "    df['building_month'] = df['building_month'].fillna(df['building_month'].median())\n",
    "    df['building_month'] = df['building_month'].astype(float)\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # 3. åœ°ä¾¡ãƒ‡ãƒ¼ã‚¿ã®çµåˆ \n",
    "    # -----------------------------------------------------\n",
    "    if not df_land.empty:\n",
    "        df_land['lat'] = df_land.geometry.y\n",
    "        df_land['lon'] = df_land.geometry.x\n",
    "        land_clean = df_land[['lat', 'lon', 'price']].dropna()\n",
    "        \n",
    "        # ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿BallTree\n",
    "        if len(land_clean) > 0:\n",
    "            land_rad = np.deg2rad(land_clean[['lat', 'lon']])\n",
    "            input_rad = np.deg2rad(df[['lat', 'lon']])\n",
    "            \n",
    "            tree = BallTree(land_rad, metric='haversine')\n",
    "            dists, indices = tree.query(input_rad, k=1)\n",
    "            \n",
    "            df['land_price'] = land_clean['price'].values[indices.flatten()]\n",
    "            df['dist_to_land_price'] = dists.flatten() * 6371 * 1000\n",
    "            df['log_land_price'] = np.log1p(df['land_price'])\n",
    "        else:\n",
    "             df['log_land_price'] = 0\n",
    "             df['dist_to_land_price'] = 0\n",
    "    else:\n",
    "        df['log_land_price'] = 0\n",
    "        df['dist_to_land_price'] = 0\n",
    "\n",
    "    # 4. åœ°ä¾¡ãƒ•ã‚£ãƒ«ã‚¿ (Trainã®ã¿)\n",
    "    # æ­£ã—ã„åœ°ä¾¡ãƒ‡ãƒ¼ã‚¿ãŒå…¥ã£ã¦ã„ã‚Œã°æœ‰åŠ¹åŒ–\n",
    "    if is_train and 'log_land_price' in df.columns:\n",
    "         df = df[df['log_land_price'] > 5] \n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # 5. ç‰¹å¾´é‡ãƒªã‚¹ãƒˆ\n",
    "    # -----------------------------------------------------\n",
    "    cat_cols = [\n",
    "        'addr1_2', \n",
    "        'rosen_name1',\n",
    "        'eki_name1',\n",
    "        'building_structure',\n",
    "        'snapshot_window_direction',\n",
    "        'madori_kind_all'\n",
    "    ]\n",
    "    for col in cat_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(str).fillna('unknown').astype('category')\n",
    "            \n",
    "    # æ•°å€¤ç‰¹å¾´é‡ã‹ã‚‰ã‚‚ station_minutes ã‚’å‰Šé™¤\n",
    "    num_features = ['unit_area', 'log_land_price', 'dist_to_land_price', 'building_month', 'station_minutes']\n",
    "    features = num_features + [c for c in cat_cols if c in df.columns]\n",
    "\n",
    "    target = None\n",
    "    if is_train:\n",
    "        # å˜ä¾¡è¨ˆç®—\n",
    "        unit_price = df['money_room'] / df['unit_area']\n",
    "        target = np.log1p(unit_price)\n",
    "\n",
    "    return df, features, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53692bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¨­å®š\n",
    "class Config:\n",
    "    n_folds = 5\n",
    "    seed = 42\n",
    "\n",
    "    run_optuna_lgb = False\n",
    "    run_optuna_cb  = False\n",
    "\n",
    "    lgb_params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'mape',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'n_jobs': -1,\n",
    "        'seed': 42,\n",
    "        'num_leaves': 64,\n",
    "        'max_depth': -1,\n",
    "        'min_child_samples': 20,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'subsample': 0.8,\n",
    "        'learning_rate': 0.1717617686033552, \n",
    "        'depth': 10, \n",
    "        'l2_leaf_reg': 2.3990529382611974e-08\n",
    "    }\n",
    "\n",
    "    cb_params = {\n",
    "        'loss_function': 'RMSE',\n",
    "        'learning_rate':  0.08642976242905503,\n",
    "        'iterations': 10000,\n",
    "        'depth': 10,\n",
    "        'random_seed': 42,\n",
    "        'verbose': 0, # ãƒ­ã‚°ã‚’å‡ºã•ãªã„\n",
    "        'early_stopping_rounds': 100,\n",
    "        'task_type': 'GPU',\n",
    "        'l2_leaf_reg': 0.0010917664921743996\n",
    "    }\n",
    "\n",
    "# æ±ç”¨ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼é–¢æ•°\n",
    "\n",
    "def train_model(model_name, X, y, test_df, params, features, cat_features):\n",
    "    print(f\"ğŸš€ {model_name} Training Started\")\n",
    "\n",
    "    kf = KFold(n_splits = Config.n_folds, shuffle = True, random_state = Config.seed)\n",
    "\n",
    "    oof_preds = np.zeros(len(X))\n",
    "    test_preds_sum = np.zeros(len(test_df))\n",
    "    cv_scores = []\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(X, y)):\n",
    "        X_train, X_val = X.iloc[train_index][features], X.iloc[val_index][features]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "        if model_name == 'LightGBM':\n",
    "            lgb_train = lgb.Dataset(X_train, y_train, categorical_feature=cat_features)\n",
    "            lgb_val = lgb.Dataset(X_val, y_val, reference = lgb_train,categorical_feature=cat_features)\n",
    "            model = lgb.train(\n",
    "                params, \n",
    "                lgb_train, \n",
    "                valid_sets = [lgb_train, lgb_val],\n",
    "                num_boost_round = 10000,\n",
    "                callbacks = [lgb.early_stopping(100, verbose=False)]\n",
    "            )\n",
    "            val_pred = model.predict(X_val)\n",
    "            test_pred = model.predict(test_df[features])\n",
    "        \n",
    "        elif model_name == 'CatBoost':\n",
    "            model = CatBoostRegressor(**params)\n",
    "            model.fit(\n",
    "                X_train, y_train,\n",
    "                eval_set=(X_val, y_val),\n",
    "                cat_features=cat_features,\n",
    "                use_best_model=True,\n",
    "                verbose=False\n",
    "            )\n",
    "            val_pred = model.predict(X_val)\n",
    "            test_pred = model.predict(test_df[features])\n",
    "        \n",
    "        #çµæœæ ¼ç´\n",
    "        oof_preds[val_index] = val_pred\n",
    "        test_preds_sum += test_pred\n",
    "\n",
    "        #ã‚¹ã‚³ã‚¢è¨ˆç®—(MAPE)\n",
    "        score = mean_absolute_percentage_error(np.expm1(y_val), np.expm1(val_pred)) * 100\n",
    "        cv_scores.append(score)\n",
    "        print(f\"  Fold {fold + 1} MAPE: {score:.4f}%\")\n",
    "\n",
    "    avg_score = np.mean(cv_scores)\n",
    "    print(f\"ğŸš€ {model_name} Training Completed. Average MAPE: {avg_score:.4f}%\\n\")\n",
    "\n",
    "    return oof_preds, test_preds_sum / Config.n_folds, avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb3f7110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optunaãƒ©ãƒƒãƒ‘ãƒ¼é–¢æ•°\n",
    "\n",
    "def run_optuna(model_name, X, y, features, cat_features):\n",
    "    print(f\"ğŸš€ {model_name} Optuna Hyperparameter Tuning Started\")\n",
    "\n",
    "    def objective(trial):\n",
    "        if model_name == 'lgbm':\n",
    "            params = {\n",
    "                'objective': 'regression', 'metric': 'rmse', 'verbosity': -1, 'boosting_type': 'gbdt',\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "                'num_leaves': trial.suggest_int('num_leaves', 32, 256),\n",
    "                'max_depth': trial.suggest_int('max_depth', 5, 12),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "                'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "            }\n",
    "        else: # catboost\n",
    "            params = {\n",
    "                'loss_function': 'RMSE', 'verbose': 0, 'early_stopping_rounds': 50, 'iterations': 1000, # æ¢ç´¢æ™‚ã¯å°‘ãªã‚ã«\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "                'depth': trial.suggest_int('depth', 4, 10),\n",
    "                'task_type': 'GPU',\n",
    "                'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-8, 10.0, log=True),\n",
    "            }\n",
    "        kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "        scores = []\n",
    "        for tr_idx, val_idx in kf.split(X, y):\n",
    "            X_tr, X_val = X.iloc[tr_idx][features], X.iloc[val_idx][features]\n",
    "            y_tr, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n",
    "            \n",
    "            if model_name == 'lgbm':\n",
    "                dtrain = lgb.Dataset(X_tr, y_tr, categorical_feature=cat_features)\n",
    "                dval = lgb.Dataset(X_val, y_val, reference=dtrain, categorical_feature=cat_features)\n",
    "                model = lgb.train(params, dtrain, valid_sets=[dval], callbacks=[lgb.early_stopping(50, verbose=False)])\n",
    "                pred = model.predict(X_val)\n",
    "            else:\n",
    "                model = CatBoostRegressor(**params, cat_features=cat_features)\n",
    "                model.fit(X_tr, y_tr, eval_set=(X_val, y_val), verbose=False)\n",
    "                pred = model.predict(X_val)\n",
    "                \n",
    "            scores.append(np.sqrt(np.mean((pred - y_val)**2))) # RMSE\n",
    "            \n",
    "        return np.mean(scores)\n",
    "\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=30) # è©¦è¡Œå›æ•°\n",
    "    print(f\"ğŸ† Best Params for {model_name}: {study.best_params}\")\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ad639e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ä¸­...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡: 10å€‹\n",
      "['unit_area', 'log_land_price', 'dist_to_land_price', 'building_month', 'station_minutes', 'addr1_2', 'rosen_name1', 'eki_name1', 'building_structure', 'madori_kind_all']\n",
      "ç‰¹å¾´é‡ã‚’ 10 å€‹ã«å³é¸ã—ã¾ã—ãŸï¼\n",
      "ä½¿ã†ç‰¹å¾´é‡ãƒªã‚¹ãƒˆ: ['unit_area', 'log_land_price', 'dist_to_land_price', 'building_month', 'station_minutes', 'addr1_2', 'rosen_name1', 'eki_name1', 'building_structure', 'madori_kind_all']\n",
      "ç‰¹å¾´é‡ã‚’ 10 å€‹ã«å³é¸ã—ã¾ã—ãŸï¼\n",
      "ä½¿ã†ç‰¹å¾´é‡ãƒªã‚¹ãƒˆ: ['unit_area', 'log_land_price', 'dist_to_land_price', 'building_month', 'station_minutes', 'addr1_2', 'rosen_name1', 'eki_name1', 'building_structure', 'madori_kind_all']\n",
      "ğŸš€ LightGBM Training Started\n",
      "  Fold 1 MAPE: 14.8569%\n",
      "  Fold 2 MAPE: 14.9425%\n",
      "  Fold 3 MAPE: 14.8103%\n",
      "  Fold 4 MAPE: 14.9476%\n",
      "  Fold 5 MAPE: 14.8400%\n",
      "ğŸš€ LightGBM Training Completed. Average MAPE: 14.8795%\n",
      "\n",
      "ğŸš€ CatBoost Training Started\n",
      "  Fold 1 MAPE: 15.5928%\n"
     ]
    }
   ],
   "source": [
    "# ãƒ¡ã‚¤ãƒ³å‡¦ç†\n",
    "# 1. ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™\n",
    "print(\"ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ä¸­...\")\n",
    "train_processed, features, target = preprocess_data(df, df_land, is_train=True)\n",
    "train_processed = train_processed.dropna(subset=['unit_area'])\n",
    "train_stats = {\n",
    "    'unit_area': train_processed['unit_area'].median(),\n",
    "    'year_built': train_processed['year_built'].median()\n",
    "}\n",
    "test_processed, _, _ = preprocess_data(test, df_land, is_train=False, fill_value=train_stats['unit_area'])\n",
    "# ã€Trainç‹¬è‡ªã®å‡¦ç†ã€‘\n",
    "# é¢ç©ãŒãªã„ãƒ‡ãƒ¼ã‚¿ã¯æ•™å¸«ã¨ã—ã¦è³ªãŒæ‚ªã„ã®ã§ã€è¡Œã”ã¨æ¶ˆã™\n",
    "\n",
    "\n",
    "\n",
    "print(f\"ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡: {len(features)}å€‹\")\n",
    "print(features)\n",
    "use_features = [f for f in features if f in train_processed.columns]\n",
    "cat_features = [c for c in use_features if train_processed[c].dtype.name == 'category']\n",
    "# â€»CatBoostç”¨ã«ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã®åå‰ãƒªã‚¹ãƒˆã‚‚ç”¨æ„\n",
    "cat_features_names = list(cat_features)\n",
    "# ç‰¹å¾´é‡ãƒªã‚¹ãƒˆï¼ˆfeaturesï¼‰ã®ç·Šæ€¥ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹\n",
    "# ç‰¹å¾´é‡ãƒªã‚¹ãƒˆï¼ˆfeaturesï¼‰ã®ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# 1. çµ¶å¯¾ã«ä½¿ã„ãŸã„æ•°å€¤ãƒ‡ãƒ¼ã‚¿\n",
    "# (å‰ã®å‡¦ç†ã§ä½œã£ãŸ station_minutes ã‚„ log_land_price ãªã©)\n",
    "num_targets = [\n",
    "    'unit_area', \n",
    "    'log_land_price', \n",
    "    'dist_to_land_price', \n",
    "    'building_month', \n",
    "    'station_minutes'\n",
    "]\n",
    "# å®Ÿéš›ã«ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«ã‚ã‚‹ã‚‚ã®ã ã‘æ®‹ã™\n",
    "final_num_features = [c for c in num_targets if c in train_processed.columns]\n",
    "\n",
    "# 2. ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ï¼ˆLightGBM/CatBoostã«ä»»ã›ã‚‹ã‚„ã¤ï¼‰\n",
    "cat_targets = [\n",
    "    'addr1_2', \n",
    "    'rosen_name1', \n",
    "    'eki_name1', \n",
    "    'building_structure', \n",
    "    'snapshot_window_direction', \n",
    "    'madori_kind_all'\n",
    "]\n",
    "# å®Ÿéš›ã«ã‚ã‚Šã€ã‹ã¤ãƒ‡ãƒ¼ã‚¿å‹ãŒã¡ã‚ƒã‚“ã¨ 'category' ã«ãªã£ã¦ã„ã‚‹ã‚‚ã®ã ã‘æ®‹ã™\n",
    "final_cat_features = [\n",
    "    c for c in cat_targets \n",
    "    if c in train_processed.columns and train_processed[c].dtype.name == 'category'\n",
    "]\n",
    "\n",
    "# 3. ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ¸ˆã¿ã®åˆ— (TE_ ã‹ã‚‰å§‹ã¾ã‚‹åˆ—)\n",
    "# ã‚‚ã—ä½œã£ã¦ã„ã‚Œã°è‡ªå‹•ã§æ‹¾ã†\n",
    "te_features = [c for c in train_processed.columns if c.startswith('TE_')]\n",
    "\n",
    "# === åˆä½“ã—ã¦ features ã‚’ä¸Šæ›¸ã ===\n",
    "features = final_num_features + final_cat_features + te_features\n",
    "\n",
    "print(f\"ç‰¹å¾´é‡ã‚’ {len(features)} å€‹ã«å³é¸ã—ã¾ã—ãŸï¼\")\n",
    "print(\"ä½¿ã†ç‰¹å¾´é‡ãƒªã‚¹ãƒˆ:\", features)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# 1. çµ¶å¯¾ã«ä½¿ã„ãŸã„æ•°å€¤ãƒ‡ãƒ¼ã‚¿\n",
    "# (å‰ã®å‡¦ç†ã§ä½œã£ãŸ station_minutes ã‚„ log_land_price ãªã©)\n",
    "num_targets = [\n",
    "    'unit_area', \n",
    "    'log_land_price', \n",
    "    'dist_to_land_price', \n",
    "    'building_month', \n",
    "    'station_minutes'\n",
    "]\n",
    "# å®Ÿéš›ã«ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«ã‚ã‚‹ã‚‚ã®ã ã‘æ®‹ã™\n",
    "final_num_features = [c for c in num_targets if c in train_processed.columns]\n",
    "\n",
    "# 2. ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ï¼ˆLightGBM/CatBoostã«ä»»ã›ã‚‹ã‚„ã¤ï¼‰\n",
    "cat_targets = [\n",
    "    'addr1_2', \n",
    "    'rosen_name1', \n",
    "    'eki_name1', \n",
    "    'building_structure', \n",
    "    'snapshot_window_direction', \n",
    "    'madori_kind_all'\n",
    "]\n",
    "# å®Ÿéš›ã«ã‚ã‚Šã€ã‹ã¤ãƒ‡ãƒ¼ã‚¿å‹ãŒã¡ã‚ƒã‚“ã¨ 'category' ã«ãªã£ã¦ã„ã‚‹ã‚‚ã®ã ã‘æ®‹ã™\n",
    "final_cat_features = [\n",
    "    c for c in cat_targets \n",
    "    if c in train_processed.columns and train_processed[c].dtype.name == 'category'\n",
    "]\n",
    "\n",
    "# 3. ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ¸ˆã¿ã®åˆ— (TE_ ã‹ã‚‰å§‹ã¾ã‚‹åˆ—)\n",
    "# ã‚‚ã—ä½œã£ã¦ã„ã‚Œã°è‡ªå‹•ã§æ‹¾ã†\n",
    "te_features = [c for c in train_processed.columns if c.startswith('TE_')]\n",
    "\n",
    "# === åˆä½“ã—ã¦ features ã‚’ä¸Šæ›¸ã ===\n",
    "features = final_num_features + final_cat_features + te_features\n",
    "\n",
    "print(f\"ç‰¹å¾´é‡ã‚’ {len(features)} å€‹ã«å³é¸ã—ã¾ã—ãŸï¼\")\n",
    "print(\"ä½¿ã†ç‰¹å¾´é‡ãƒªã‚¹ãƒˆ:\", features)\n",
    "\n",
    "# 2. OptunaãŒå¿…è¦ãªã‚‰å›ã™\n",
    "if Config.run_optuna_lgb:\n",
    "    best_p = run_optuna('LightGBM', train_processed, target, features, final_cat_features)\n",
    "    Config.lgb_params.update(best_p) # çµæœã‚’Configã«ä¸Šæ›¸ã\n",
    "\n",
    "if Config.run_optuna_cb:\n",
    "    best_p = run_optuna('CatBoost', train_processed, target, features, cat_features_names)\n",
    "    Config.cb_params.update(best_p)\n",
    "\n",
    "# 3. LightGBM å­¦ç¿’\n",
    "oof_lgb, pred_lgb, score_lgb = train_model(\n",
    "    'LightGBM', train_processed, target, test_processed, \n",
    "    Config.lgb_params, features, cat_features\n",
    ")\n",
    "\n",
    "# 4. CatBoost å­¦ç¿’\n",
    "oof_cb, pred_cb, score_cb = train_model(\n",
    "    'CatBoost', train_processed, target, test_processed, \n",
    "    Config.cb_params, features, cat_features_names  \n",
    ")\n",
    "\n",
    "# 5. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ« (åŠ é‡å¹³å‡)\n",
    "# å˜ç´”å¹³å‡(0.5ãšã¤).CVã‚¹ã‚³ã‚¢ãŒè‰¯ã„æ–¹ã‚’å°‘ã—é‡ãã™ã‚‹ã®ã‚‚ã‚¢ãƒª\n",
    "weight_lgb = 0.5\n",
    "weight_cb = 0.5\n",
    "\n",
    "final_log_pred = (pred_lgb * weight_lgb) + (pred_cb * weight_cb)\n",
    "final_oof = (oof_lgb * weight_lgb) + (oof_cb * weight_cb)\n",
    "\n",
    "# æœ€çµ‚ã‚¹ã‚³ã‚¢ç¢ºèª\n",
    "final_cv = mean_absolute_percentage_error(np.expm1(target), np.expm1(final_oof)) * 100\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(f\"LightGBM CV: {score_lgb:.4f}%\")\n",
    "print(f\"CatBoost CV: {score_cb:.4f}%\")\n",
    "print(f\"Ensemble CV: {final_cv:.4f}%  <-- ã“ã‚ŒãŒæœ€çµ‚ã‚¹ã‚³ã‚¢ï¼\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# 6. CSVä½œæˆ\n",
    "submission = pd.DataFrame({'id': test['id'], 'prediction': np.expm1(final_log_pred) * test_processed['unit_area']})\n",
    "submission.to_csv('submission_ensemble.csv', index=False, header=False)\n",
    "print(\"submission_ensemble.csv Saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
