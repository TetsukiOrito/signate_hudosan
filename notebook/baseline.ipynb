{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfbac98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 21431 entries, 0 to 21430\n",
      "Columns: 140 entries, L02_001 to geometry\n",
      "dtypes: float64(4), geometry(1), int32(69), object(66)\n",
      "memory usage: 17.2+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import warnings\n",
    "from sklearn.neighbors import BallTree\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "input_path = '../input/'\n",
    "gdf_land = gpd.read_file(os.path.join(input_path, 'L02-25.geojson'))\n",
    "df_land = gdf_land.copy()\n",
    "df_land['price'] = df_land['L02_006']\n",
    "df = pd.read_csv(os.path.join(input_path, 'train.csv'))\n",
    "test = pd.read_csv(os.path.join(input_path, 'test.csv'))\n",
    "gdf_land.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e64d7d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import BallTree\n",
    "\n",
    "def preprocess_data(input_df, df_land, is_train=True):\n",
    "    \"\"\"\n",
    "    駅情報は一旦無視！\n",
    "    「巨大なゴミデータ」の削除と、「地価・築年数」だけに集中したシンプル版\n",
    "    \"\"\"\n",
    "    df = input_df.copy()\n",
    "    \n",
    "    # -----------------------------------------------------\n",
    "    # 0. 【Trainのみ】ハズレ値などの削除\n",
    "    # -----------------------------------------------------\n",
    "    if is_train:\n",
    "        # 1. 面積フィルタ\n",
    "        # 面積500㎡以上はカット\n",
    "        df = df[df['unit_area'] < 500] \n",
    "        \n",
    "        # 2. 単価がおかしい土地を削除\n",
    "        # 単価(円/㎡)を計算\n",
    "        temp_unit_price = df['money_room'] / df['unit_area']\n",
    "        \n",
    "        # 「単価が1万円/㎡ 以下」は、原野や山林なので捨てる\n",
    "        df = df[temp_unit_price > 10000] \n",
    "        \n",
    "        # 3. 「高すぎる単価」もノイズになるのでキャップを設ける\n",
    "        df = df[temp_unit_price < 10000000]\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # 1. 駅情報 (今後実装予定)\n",
    "    # -----------------------------------------------------\n",
    "    # ※カラム名が画像通り (bus_time1, walk_distance1) 前提で書きます\n",
    "    # もし違ったら df.columns で確認して書き換えてください！\n",
    "    \n",
    "    # 必要な列があるか確認\n",
    "    if 'walk_distance1' in df.columns:\n",
    "        \n",
    "        def calc_access_time(row, suffix):\n",
    "            \"\"\"\n",
    "            suffix: '1' または '2' を指定\n",
    "            \"\"\"\n",
    "            # 1. データの取得 (欠損値は0にしておく)\n",
    "            w_dist = row.get(f'walk_distance{suffix}', np.nan)\n",
    "            b_time = row.get(f'bus_time{suffix}', np.nan)\n",
    "            \n",
    "            # データが全くない場合は「不明(無限大)」\n",
    "            if pd.isna(w_dist) and pd.isna(b_time):\n",
    "                return 999.0 # あとでminを取るときに負けるように大きくする\n",
    "\n",
    "            # NaNを0扱いで計算用に確保\n",
    "            w_dist_val = 0 if pd.isna(w_dist) else w_dist\n",
    "            b_time_val = 0 if pd.isna(b_time) else b_time\n",
    "            \n",
    "            # 2. 徒歩時間を計算 (80m = 1分\n",
    "            walk_min = w_dist_val / 80.0\n",
    "            \n",
    "            # 3. ロジック分岐\n",
    "            if b_time_val > 0:\n",
    "                # 【パターンA: バス利用】\n",
    "                # 時間 = バス乗車時間 + バス停からの徒歩 + 待ち時間ペナルティ(10分)\n",
    "                return b_time_val + walk_min + 10.0\n",
    "            else:\n",
    "                # 【パターンB: 徒歩のみ】\n",
    "                # 時間 = 駅からの徒歩\n",
    "                return walk_min\n",
    "\n",
    "        # ルート1とルート2、それぞれの所要時間を計算\n",
    "        df['access_time_1'] = df.apply(lambda x: calc_access_time(x, '1'), axis=1)\n",
    "        df['access_time_2'] = df.apply(lambda x: calc_access_time(x, '2'), axis=1)\n",
    "        \n",
    "        # 「1」と「2」のうち、時間が短い方（＝近い方）を採用！\n",
    "        # どっちも999(不明)なら、最終的に120分で埋める\n",
    "        df['station_minutes'] = df[['access_time_1', 'access_time_2']].min(axis=1)\n",
    "        \n",
    "        # 最終的な欠損値埋め (田舎対策)\n",
    "        # 999のまま残ったやつは「駅徒歩圏外」として120分にする\n",
    "        df['station_minutes'] = df['station_minutes'].replace(999.0, 120.0)\n",
    "        \n",
    "        # 念のため station_minutes 自体がNaNのやつも埋める\n",
    "        df['station_minutes'] = df['station_minutes'].fillna(120.0)\n",
    "\n",
    "        # 不要になった一時的な列を削除（メモリ節約）\n",
    "        df.drop(['access_time_1', 'access_time_2'], axis=1, inplace=True)\n",
    "        \n",
    "        # カテゴリ用 (沿線名などは _1 の方を正として採用しておく)\n",
    "        if 'rosen_name1' in df.columns:\n",
    "            df['line_name'] = df['rosen_name1']\n",
    "            df['station_name'] = df['eki_name1']\n",
    "        else:\n",
    "            df['line_name'] = 'unknown'\n",
    "            df['station_name'] = 'unknown'\n",
    "\n",
    "    else:\n",
    "        # そもそも列がない場合\n",
    "        df['station_minutes'] = 120.0\n",
    "        df['line_name'] = 'unknown'\n",
    "        df['station_name'] = 'unknown'\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # 2. 築年数の計算 \n",
    "    # -----------------------------------------------------\n",
    "    df['year_built'] = pd.to_numeric(df['year_built'], errors='coerce')\n",
    "    df['year_built'] = df['year_built'].fillna(df['year_built'].median())\n",
    "    df['temp_time'] = pd.to_datetime(df['year_built'].astype(int).astype(str), format='%Y%m', errors='coerce')\n",
    "    \n",
    "    base_date = pd.to_datetime('2025-12-01')\n",
    "    df['building_month'] = (base_date - df['temp_time']).dt.days / 30.44\n",
    "    df['building_month'] = df['building_month'].fillna(df['building_month'].median())\n",
    "    df['building_month'] = df['building_month'].astype(float)\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # 3. 地価データの結合 \n",
    "    # -----------------------------------------------------\n",
    "    if not df_land.empty:\n",
    "        df_land['lat'] = df_land.geometry.y\n",
    "        df_land['lon'] = df_land.geometry.x\n",
    "        land_clean = df_land[['lat', 'lon', 'price']].dropna()\n",
    "        \n",
    "        # データがある場合のみBallTree\n",
    "        if len(land_clean) > 0:\n",
    "            land_rad = np.deg2rad(land_clean[['lat', 'lon']])\n",
    "            input_rad = np.deg2rad(df[['lat', 'lon']])\n",
    "            \n",
    "            tree = BallTree(land_rad, metric='haversine')\n",
    "            dists, indices = tree.query(input_rad, k=1)\n",
    "            \n",
    "            df['land_price'] = land_clean['price'].values[indices.flatten()]\n",
    "            df['dist_to_land_price'] = dists.flatten() * 6371 * 1000\n",
    "            df['log_land_price'] = np.log1p(df['land_price'])\n",
    "        else:\n",
    "             df['log_land_price'] = 0\n",
    "             df['dist_to_land_price'] = 0\n",
    "    else:\n",
    "        df['log_land_price'] = 0\n",
    "        df['dist_to_land_price'] = 0\n",
    "\n",
    "    # 4. 地価フィルタ (Trainのみ)\n",
    "    # 正しい地価データが入っていれば有効化\n",
    "    if is_train and 'log_land_price' in df.columns:\n",
    "         df = df[df['log_land_price'] > 5] \n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # 5. 特徴量リスト\n",
    "    # -----------------------------------------------------\n",
    "    cat_cols = [\n",
    "        'addr1_2', \n",
    "        'rosen_name1',\n",
    "        'eki_name1',\n",
    "        'building_structure',\n",
    "        'snapshot_window_direction',\n",
    "        'madori_kind_all'\n",
    "    ]\n",
    "    for col in cat_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(str).fillna('unknown').astype('category')\n",
    "            \n",
    "    # 数値特徴量からも station_minutes を削除\n",
    "    num_features = ['unit_area', 'log_land_price', 'dist_to_land_price', 'building_month', 'station_minutes']\n",
    "    features = num_features + [c for c in cat_cols if c in df.columns]\n",
    "\n",
    "    target = None\n",
    "    if is_train:\n",
    "        # 単価計算\n",
    "        unit_price = df['money_room'] / df['unit_area']\n",
    "        target = np.log1p(unit_price)\n",
    "\n",
    "    return df, features, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3711c27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "前処理を実行中...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用する特徴量: 10個\n",
      "['unit_area', 'log_land_price', 'dist_to_land_price', 'building_month', 'station_minutes', 'addr1_2', 'rosen_name1', 'eki_name1', 'building_structure', 'madori_kind_all']\n",
      "\n",
      "モデル学習中...\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001165 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5882\n",
      "[LightGBM] [Info] Number of data points in the train set: 253379, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 12.476830\n",
      "予測を実行中...\n",
      "CSV作成中...\n",
      "\n",
      "完了！ 'submission.csv' が保存されました。\n",
      "先頭5行はこんな感じです↓\n",
      "   id    prediction\n",
      "0   0  1.373621e+07\n",
      "1   1  3.096080e+07\n",
      "2   2  1.349060e+07\n",
      "3   3  2.711284e+07\n",
      "4   4  1.735203e+07\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 1. 前処理 (Train & Test)\n",
    "# ---------------------------------------------------------\n",
    "print(\"前処理を実行中...\")\n",
    "\n",
    "# Trainデータの処理 (学習用なので is_train=True)\n",
    "# ※ preprocess_data関数はさっき定義した最新版を使ってください\n",
    "train_processed, features, target = preprocess_data(df, df_land, is_train=True)\n",
    "# 【Train独自の処理】\n",
    "# 面積がないデータは「教師として質が悪い」ので、行ごと消す\n",
    "train_processed = train_processed.dropna(subset=['unit_area'])\n",
    "\n",
    "# 削除した分、target（目的変数）も合わせる必要があるので、再計算するか\n",
    "# あるいは preprocess_data の中で dropna してから target を作るのが安全ですが、\n",
    "# 今の段階なら「埋めるための値（中央値）」をここで計算して保存しておくのが大事です。\n",
    "\n",
    "# ★Testを埋めるための「正解の値」をキープ！\n",
    "fill_value = train_processed['unit_area'].median() \n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. Testデータの処理\n",
    "# ---------------------------------------------------------\n",
    "# 先に関数を通す\n",
    "test_processed, _, _ = preprocess_data(test, df_land, is_train=False)\n",
    "\n",
    "# 【Test独自の処理】\n",
    "# 提出用なので行は消せない。「Trainの中央値」を使って埋める\n",
    "test_processed['unit_area'] = test_processed['unit_area'].fillna(fill_value)\n",
    "print(f\"使用する特徴量: {len(features)}個\")\n",
    "print(features)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. モデル学習 & 予測 (K-Fold アンサンブル)\n",
    "# ---------------------------------------------------------\n",
    "print(\"\\nモデル学習 & K-Fold予測中...\")\n",
    "\n",
    "# 5分割する\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# テストデータへの予測値を格納する配列（0で初期化）\n",
    "test_preds_sum = np.zeros(len(test_processed))\n",
    "oof_preds = np.zeros(len(train_processed)) # 手元の検証用\n",
    "\n",
    "# 特徴量リストの整理\n",
    "use_features = [f for f in features if f in train_processed.columns]\n",
    "cat_features = [c for c in use_features if train_processed[c].dtype.name == 'category']\n",
    "\n",
    "# 評価スコア計算用\n",
    "cv_scores = []\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(train_processed, target)):\n",
    "    # データの分割\n",
    "    X_tr, X_val = train_processed.iloc[train_index][use_features], train_processed.iloc[val_index][use_features]\n",
    "    y_tr, y_val = target.iloc[train_index], target.iloc[val_index]\n",
    "    \n",
    "    # データセット作成\n",
    "    lgb_train = lgb.Dataset(X_tr, y_tr, categorical_feature=cat_features)\n",
    "    lgb_val = lgb.Dataset(X_val, y_val, reference=lgb_train, categorical_feature=cat_features)\n",
    "    \n",
    "    # 手動パラメータ（Optunaで悪化したなら、一旦これらを使うのが安全）\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'mape',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'n_jobs': -1,\n",
    "        'seed': 42,\n",
    "        'learning_rate': 0.05,\n",
    "        'num_leaves': 64,\n",
    "        'max_depth': -1,\n",
    "        'min_child_samples': 20,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'subsample': 0.8,\n",
    "    }\n",
    "    \n",
    "    # 学習\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        lgb_train,\n",
    "        valid_sets=[lgb_train, lgb_val],\n",
    "        num_boost_round=10000,\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=100, verbose=False),\n",
    "            lgb.log_evaluation(0) # ログを黙らせる\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # 1. 検証データへの予測 (対数を戻してスコア計算)\n",
    "    val_pred_log = model.predict(X_val)\n",
    "    oof_preds[val_index] = val_pred_log\n",
    "    \n",
    "    # 手元のMAPEスコア確認\n",
    "    score = mean_absolute_percentage_error(np.expm1(y_val), np.expm1(val_pred_log)) * 100\n",
    "    cv_scores.append(score)\n",
    "    print(f\"Fold {fold+1} MAPE: {score:.4f}%\")\n",
    "    \n",
    "    # 2. テストデータへの予測 (加算していく)\n",
    "    test_preds_sum += model.predict(test_processed[use_features])\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 結果の集計\n",
    "# ---------------------------------------------------------\n",
    "print(\"=\"*30)\n",
    "print(f\"平均 CV MAPE: {np.mean(cv_scores):.4f}%\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "# テストデータの予測値を「5で割って平均」にする\n",
    "avg_pred_log = test_preds_sum / 5\n",
    "\n",
    "# 対数を戻す (log -> exp)\n",
    "pred_price_per_m2 = np.expm1(avg_pred_log)\n",
    "\n",
    "# 単価 × 面積 ＝ 総額\n",
    "pred_total_price = pred_price_per_m2 * test_processed['unit_area']\n",
    "\n",
    "# 以下、CSV作成は元のコードと同じでOK\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. 提出用CSVの作成\n",
    "# ---------------------------------------------------------\n",
    "print(\"CSV作成中...\")\n",
    "\n",
    "# id列と予測値をくっつける\n",
    "submission = pd.DataFrame({\n",
    "    'id': test['id'],         # テストデータのID\n",
    "    'prediction': pred_total_price # 予測した総額\n",
    "})\n",
    "\n",
    "# CSVに書き出し (header=Falseが必要な場合が多いので注意)\n",
    "# 今回は「id,値段」の形式ということなので、ヘッダーありかなしか確認してください。\n",
    "# 多くの場合、SIGNATEなどはヘッダー不要(header=False)か、指定のヘッダー名が必要です。\n",
    "# ここでは一旦、一般的な「ヘッダーなし」で保存します。\n",
    "submission.to_csv('submission.csv', index=False, header=False)\n",
    "\n",
    "print(\"\\n完了！ 'submission.csv' が保存されました。\")\n",
    "print(\"先頭5行はこんな感じです↓\")\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5436ee2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "もとのデータ数：112437 行、予測データ数：112437 行\n"
     ]
    }
   ],
   "source": [
    "print(f\"もとのデータ数：{len(test)} 行、予測データ数：{len(submission)} 行\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ece8d3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id            0\n",
      "prediction    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(submission.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c29a455",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-20 22:23:57,731] A new study created in memory with name: no-name-98818113-1963-4e7a-9978-7f8e838c1b1f\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "\n",
    "def objective(trial):\n",
    "    # ---------------------------------------------------------\n",
    "    # 1. チューニングしたいパラメータの範囲を定義\n",
    "    # ---------------------------------------------------------\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',      # log(price)のRMSEを最小化すれば、MAPEも良くなる\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'n_jobs': -1,\n",
    "        'seed': 42,\n",
    "        \n",
    "        # 探索する変数たち\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 32, 256),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 15),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "    }\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 2. 高速な交差検証 (K-Fold)\n",
    "    # ---------------------------------------------------------\n",
    "    # 毎回全データでやると重いので、データが多い場合は 3-Fold くらいで探索するのがコツ\n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    # スコア格納用\n",
    "    rmses = []\n",
    "    \n",
    "    # カテゴリ変数の指定\n",
    "    # featuresリストに入っているカテゴリ変数を抽出\n",
    "    cat_features = [c for c in features if train_processed[c].dtype.name == 'category']\n",
    "    \n",
    "    # KFoldループ（LightGBMのcv関数を使うともっと速いですが、わかりやすく手動ループにします）\n",
    "    for train_index, val_index in kf.split(train_processed, target):\n",
    "        X_train, X_val = train_processed.iloc[train_index][features], train_processed.iloc[val_index][features]\n",
    "        y_train, y_val = target.iloc[train_index], target.iloc[val_index]\n",
    "        \n",
    "        # データセット作成\n",
    "        lgb_train = lgb.Dataset(X_train, y_train, categorical_feature=cat_features)\n",
    "        lgb_val = lgb.Dataset(X_val, y_val, reference=lgb_train, categorical_feature=cat_features)\n",
    "        \n",
    "        # Pruning（ダメそうな試行は早めに打ち切る機能）を有効化\n",
    "        pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"rmse\")\n",
    "        \n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            lgb_train,\n",
    "            valid_sets=[lgb_val],\n",
    "            num_boost_round=10000,  # 多めに設定\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(stopping_rounds=50, verbose=False),\n",
    "                pruning_callback\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # 検証スコア (RMSE) を記録\n",
    "        preds = model.predict(X_val)\n",
    "        rmse = np.sqrt(np.mean((preds - y_val)**2))\n",
    "        rmses.append(rmse)\n",
    "    \n",
    "    return np.mean(rmses)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. 探索実行！ (ここから時間がかかります)\n",
    "# ---------------------------------------------------------\n",
    "study = optuna.create_study(direction='minimize') # RMSEを最小化したい\n",
    "study.optimize(objective, n_trials=50) # 50回試行（時間は調整してください）\n",
    "\n",
    "print(\"=\"*30)\n",
    "print(\"Best Valid RMSE:\", study.best_value)\n",
    "print(\"Best Params:\", study.best_params)\n",
    "print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70390bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==駅情報のサンプル表示\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bus_time1</th>\n",
       "      <th>walk_distance1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123380</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36050</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99127</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199249</th>\n",
       "      <td>NaN</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308831</th>\n",
       "      <td>NaN</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20211</th>\n",
       "      <td>NaN</td>\n",
       "      <td>640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98858</th>\n",
       "      <td>NaN</td>\n",
       "      <td>320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356737</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56729</th>\n",
       "      <td>NaN</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295701</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268015</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32690</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354811</th>\n",
       "      <td>NaN</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278449</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91886</th>\n",
       "      <td>NaN</td>\n",
       "      <td>800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150558</th>\n",
       "      <td>NaN</td>\n",
       "      <td>800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183770</th>\n",
       "      <td>8.0</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206761</th>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40432</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1520.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113216</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185953</th>\n",
       "      <td>NaN</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252852</th>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239124</th>\n",
       "      <td>NaN</td>\n",
       "      <td>880.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104556</th>\n",
       "      <td>NaN</td>\n",
       "      <td>11000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307370</th>\n",
       "      <td>NaN</td>\n",
       "      <td>320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298463</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294179</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24115</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59856</th>\n",
       "      <td>NaN</td>\n",
       "      <td>320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88225</th>\n",
       "      <td>NaN</td>\n",
       "      <td>960.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278185</th>\n",
       "      <td>NaN</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158899</th>\n",
       "      <td>NaN</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277038</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10921</th>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158013</th>\n",
       "      <td>NaN</td>\n",
       "      <td>640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73220</th>\n",
       "      <td>NaN</td>\n",
       "      <td>640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184311</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188828</th>\n",
       "      <td>NaN</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292251</th>\n",
       "      <td>26.0</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274071</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26164</th>\n",
       "      <td>NaN</td>\n",
       "      <td>800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41639</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272430</th>\n",
       "      <td>NaN</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141965</th>\n",
       "      <td>NaN</td>\n",
       "      <td>560.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316802</th>\n",
       "      <td>NaN</td>\n",
       "      <td>960.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342861</th>\n",
       "      <td>NaN</td>\n",
       "      <td>800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318928</th>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199328</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258974</th>\n",
       "      <td>NaN</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67014</th>\n",
       "      <td>NaN</td>\n",
       "      <td>720.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bus_time1  walk_distance1\n",
       "123380        NaN          1040.0\n",
       "36050         NaN          1280.0\n",
       "99127         NaN          1040.0\n",
       "199249        NaN           400.0\n",
       "308831        NaN           240.0\n",
       "20211         NaN           640.0\n",
       "98858         NaN           320.0\n",
       "356737        NaN          1200.0\n",
       "56729         NaN           240.0\n",
       "295701        NaN          1280.0\n",
       "268015        NaN          1200.0\n",
       "32690         NaN          1200.0\n",
       "354811        NaN           160.0\n",
       "278449        NaN          1200.0\n",
       "91886         NaN           800.0\n",
       "150558        NaN           800.0\n",
       "183770        8.0           160.0\n",
       "206761        0.0           240.0\n",
       "40432         NaN          1520.0\n",
       "113216        NaN          1440.0\n",
       "185953        NaN           160.0\n",
       "252852        NaN            80.0\n",
       "239124        NaN           880.0\n",
       "104556        NaN         11000.0\n",
       "307370        NaN           320.0\n",
       "298463        NaN          1200.0\n",
       "294179        NaN          1280.0\n",
       "24115         NaN          1840.0\n",
       "59856         NaN           320.0\n",
       "88225         NaN           960.0\n",
       "278185        NaN           400.0\n",
       "158899        NaN           160.0\n",
       "277038        NaN          1200.0\n",
       "10921         NaN            80.0\n",
       "158013        NaN           640.0\n",
       "73220         NaN           640.0\n",
       "184311        NaN          2400.0\n",
       "188828        NaN           160.0\n",
       "292251       26.0           240.0\n",
       "274071        0.0          1280.0\n",
       "26164         NaN           800.0\n",
       "41639         NaN          1200.0\n",
       "272430        NaN           480.0\n",
       "141965        NaN           560.0\n",
       "316802        NaN           960.0\n",
       "342861        NaN           800.0\n",
       "318928        0.0           400.0\n",
       "199328        NaN          1040.0\n",
       "258974        NaN           400.0\n",
       "67014         NaN           720.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 駅情報のEDA.\n",
    "\n",
    "print(\"==駅情報のサンプル表示\")\n",
    "train_processed[['bus_time1', 'walk_distance1']].sample(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211ffb9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
